# Text-to-Speech system with expressiveness control based on diffusion probabilistic models

## Abstract

This thesis describes the research and experiments behind a TTS system aimed at generating natural human speech with expressiveness controllability. The resulting system is an attempt to tackle problems traditional approaches struggle with, such as lack of speech naturalness, insufficient systems' flexibility and the so called "one-to-many mapping problem". The neural networks-based backbone of the system is data-driven, what allows to flexibly adjust it to either new data or different synthesis setups. The gap between the utterance's content and its style is alleviated by controlling the generated speech's style with Global Style tokens. In order to ensure diversity of the speaking style and to reduce the model's dependence on external inputs, the system is equipped with a module for style embedding prediction based on Denoising Diffusion Probabilistic Models. 

## Introduction

Text-to-Speech systems have undergone significant development over the last several years with the emerging domination of neural networks-based approaches.

### Goals

### Related work

## Theoretical foundation

### Neural networks-based architectures

#### Convolutional layers

#### Recurrent layers

#### Attention

### 

## Proposed system

## Experiments

## Conclusions

### Further research
